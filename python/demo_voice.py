#!/usr/bin/env python3
"""
Demo Voice - è¯­éŸ³äº¤äº’æ¼”ç¤º

æ”¯æŒè¯­éŸ³è¾“å…¥å’Œè¯­éŸ³è¾“å‡ºçš„å®Œæ•´äº¤äº’æ¼”ç¤º
"""

import asyncio
import sys
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from rich.console import Console
from rich.panel import Panel
from rich.live import Live
from rich.spinner import Spinner
from rich.text import Text

console = Console()


def print_banner():
    """æ‰“å°æ¬¢è¿æ¨ªå¹…"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                              â•‘
â•‘        ğŸ¤  æ™ºèƒ½åº§èˆ±è¯­éŸ³äº¤äº’ç³»ç»Ÿ  ğŸ”Š                          â•‘
â•‘            Voice Cockpit Assistant                           â•‘
â•‘                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    console.print(banner, style="bold cyan")


async def main(model_path: str, n_ctx: int = 4096, n_gpu_layers: int = 35,
               asr_model: str = "small", tts_voice: str = "xiaoxiao"):
    """ä¸»å‡½æ•°"""
    print_banner()
    
    # æ£€æŸ¥ä¾èµ–
    try:
        from voice_interface import (
            CockpitVoiceAssistant, VoiceInterface,
            ASRConfig, TTSConfig, HAS_WHISPER, HAS_EDGE_TTS, HAS_SOUNDDEVICE
        )
    except ImportError as e:
        console.print(f"[red]å¯¼å…¥é”™è¯¯: {e}[/red]")
        console.print("[yellow]è¯·ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–[/yellow]")
        return
    
    # æ£€æŸ¥å¯ç”¨åŠŸèƒ½
    console.print("\n[bold]ç³»ç»Ÿæ£€æŸ¥:[/bold]")
    console.print(f"  ASR (Whisper): {'âœ… å¯ç”¨' if HAS_WHISPER else 'âŒ ä¸å¯ç”¨'}")
    console.print(f"  TTS (Edge TTS): {'âœ… å¯ç”¨' if HAS_EDGE_TTS else 'âŒ ä¸å¯ç”¨'}")
    console.print(f"  éŸ³é¢‘è®¾å¤‡: {'âœ… å¯ç”¨' if HAS_SOUNDDEVICE else 'âŒ ä¸å¯ç”¨'}")
    
    if not HAS_SOUNDDEVICE:
        console.print("\n[yellow]è­¦å‘Š: éŸ³é¢‘è®¾å¤‡ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ–‡æœ¬æ¨¡å¼[/yellow]")
        console.print("[yellow]è¯·å®‰è£…: pip install sounddevice[/yellow]\n")
        
        # å›é€€åˆ°æ–‡æœ¬æ¨¡å¼
        from demo_text import main as text_main
        await text_main(model_path, n_ctx, n_gpu_layers)
        return
    
    # é…ç½®
    asr_config = ASRConfig(
        model_size=asr_model,
        device="cuda" if n_gpu_layers > 0 else "cpu",
        language="zh"
    )
    
    tts_config = TTSConfig()
    
    # TTSè¯­éŸ³æ˜ å°„
    voice_map = {
        "xiaoxiao": "zh-CN-XiaoxiaoNeural",
        "xiaoyi": "zh-CN-XiaoyiNeural",
        "yunjian": "zh-CN-YunjianNeural",
        "yunxi": "zh-CN-YunxiNeural",
    }
    tts_config.voice = voice_map.get(tts_voice, tts_voice)
    
    console.print(f"\n[dim]æ¨¡å‹è·¯å¾„: {model_path}[/dim]")
    console.print(f"[dim]ASRæ¨¡å‹: {asr_model}[/dim]")
    console.print(f"[dim]TTSè¯­éŸ³: {tts_voice}[/dim]\n")
    
    # åˆå§‹åŒ–
    with console.status("[bold green]æ­£åœ¨åŠ è½½æ¨¡å‹...", spinner="dots"):
        try:
            assistant = CockpitVoiceAssistant(
                model_path=model_path,
                asr_config=asr_config,
                tts_config=tts_config
            )
            
            # é¢„çƒ­ASRæ¨¡å‹
            if HAS_WHISPER:
                assistant.voice.asr.initialize()
                
        except Exception as e:
            console.print(f"[red]åˆå§‹åŒ–å¤±è´¥: {e}[/red]")
            return
    
    console.print("[green]âœ“ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼[/green]\n")
    
    # ä½¿ç”¨è¯´æ˜
    console.print(Panel(
        "[bold]ä½¿ç”¨è¯´æ˜:[/bold]\n\n"
        "â€¢ æŒ‰ [bold]Enter[/bold] å¼€å§‹è¯´è¯\n"
        "â€¢ è¯´å®Œåç­‰å¾…è‡ªåŠ¨è¯†åˆ«\n"
        "â€¢ è¾“å…¥ [bold]quit[/bold] é€€å‡º\n"
        "â€¢ è¾“å…¥ [bold]text[/bold] åˆ‡æ¢åˆ°æ–‡æœ¬æ¨¡å¼",
        title="è¯­éŸ³æ¨¡å¼",
        border_style="cyan"
    ))
    
    text_mode = False
    
    # ä¸»å¾ªç¯
    while True:
        try:
            if text_mode:
                # æ–‡æœ¬è¾“å…¥æ¨¡å¼
                user_input = console.input("\n[bold blue]You (æ–‡æœ¬):[/bold blue] ").strip()
                
                if not user_input:
                    continue
                
                if user_input.lower() in ["quit", "exit", "q"]:
                    break
                
                if user_input.lower() == "voice":
                    text_mode = False
                    console.print("[green]å·²åˆ‡æ¢åˆ°è¯­éŸ³æ¨¡å¼[/green]")
                    continue
                
                # å¤„ç†æ–‡æœ¬è¾“å…¥
                console.print("[bold green]Assistant:[/bold green] ", end="")
                
                response_text = ""
                async for token in assistant.assistant.chat(user_input):
                    console.print(token, end="", highlight=False)
                    response_text += token
                
                console.print()
                
                # TTSæ’­æŠ¥
                if HAS_EDGE_TTS:
                    clean_text = _clean_for_tts(response_text)
                    if clean_text:
                        with console.status("[dim]æ­£åœ¨æ’­æŠ¥...[/dim]"):
                            await assistant.voice.speak(clean_text)
                
            else:
                # è¯­éŸ³è¾“å…¥æ¨¡å¼
                console.print("\n[bold cyan]æŒ‰ Enter å¼€å§‹è¯´è¯...[/bold cyan]", end="")
                cmd = console.input("")
                
                if cmd.lower() in ["quit", "exit", "q"]:
                    break
                
                if cmd.lower() == "text":
                    text_mode = True
                    console.print("[green]å·²åˆ‡æ¢åˆ°æ–‡æœ¬æ¨¡å¼[/green]")
                    continue
                
                # å¼€å§‹å½•éŸ³
                console.print("[yellow]ğŸ¤ æ­£åœ¨å¬...[/yellow]")
                
                try:
                    # å½•åˆ¶å¹¶è¯†åˆ«
                    user_text = await assistant.voice.listen(duration=5.0)
                    
                    if not user_text:
                        console.print("[dim]æœªæ£€æµ‹åˆ°è¯­éŸ³[/dim]")
                        continue
                    
                    console.print(f"[bold blue]You:[/bold blue] {user_text}")
                    
                    # è·å–å“åº”
                    console.print("[bold green]Assistant:[/bold green] ", end="")
                    
                    response_text = ""
                    async for token in assistant.assistant.chat(user_text):
                        console.print(token, end="", highlight=False)
                        response_text += token
                    
                    console.print()
                    
                    # TTSæ’­æŠ¥
                    if HAS_EDGE_TTS:
                        clean_text = _clean_for_tts(response_text)
                        if clean_text:
                            with console.status("[dim]æ­£åœ¨æ’­æŠ¥...[/dim]"):
                                await assistant.voice.speak(clean_text)
                    
                except Exception as e:
                    console.print(f"[red]é”™è¯¯: {e}[/red]")
                    
        except KeyboardInterrupt:
            console.print("\n\n[yellow]å·²ä¸­æ–­[/yellow]")
            break
    
    console.print("\n[yellow]å†è§ï¼ç¥æ‚¨è¡Œè½¦å®‰å…¨ï¼ğŸš—[/yellow]\n")


def _clean_for_tts(text: str) -> str:
    """æ¸…ç†æ–‡æœ¬ç”¨äºTTS"""
    import re
    # ç§»é™¤JSON
    cleaned = re.sub(r'\{[^}]+\}', '', text)
    # ç§»é™¤ç‰¹æ®Šç¬¦å·
    cleaned = re.sub(r'[âœ…âŒğŸ”§ğŸ“ŠğŸ”‹ğŸ›ğŸ›¢ï¸ğŸ“ğŸŒ¡ï¸]', '', cleaned)
    # ç§»é™¤å¤šä½™ç©ºç™½
    cleaned = ' '.join(cleaned.split())
    return cleaned.strip()


def run():
    """è¿è¡Œå…¥å£"""
    parser = argparse.ArgumentParser(
        description="æ™ºèƒ½åº§èˆ±åŠ©æ‰‹ - è¯­éŸ³äº¤äº’æ¼”ç¤º"
    )
    parser.add_argument(
        "model_path",
        nargs="?",
        default="models/qwen2.5-7b-instruct-q4_k_m.gguf",
        help="æ¨¡å‹æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "-c", "--ctx",
        type=int,
        default=4096,
        help="ä¸Šä¸‹æ–‡é•¿åº¦ (é»˜è®¤: 4096)"
    )
    parser.add_argument(
        "-g", "--gpu-layers",
        type=int,
        default=35,
        help="GPUå±‚æ•° (é»˜è®¤: 35)"
    )
    parser.add_argument(
        "--asr-model",
        default="small",
        choices=["tiny", "base", "small", "medium", "large"],
        help="Whisperæ¨¡å‹å¤§å° (é»˜è®¤: small)"
    )
    parser.add_argument(
        "--tts-voice",
        default="xiaoxiao",
        choices=["xiaoxiao", "xiaoyi", "yunjian", "yunxi"],
        help="TTSè¯­éŸ³ (é»˜è®¤: xiaoxiao)"
    )
    
    args = parser.parse_args()
    asyncio.run(main(
        args.model_path,
        args.ctx,
        args.gpu_layers,
        args.asr_model,
        args.tts_voice
    ))


if __name__ == "__main__":
    run()
